{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "base_images_dir = Path(\"../Dataset_emocional\")\n",
    "\n",
    "if not base_images_dir.exists():\n",
    "    raise FileNotFoundError(f\"No se encontró: {base_images_dir.resolve()}\")\n",
    "\n",
    "print(f\"✓ Dataset encontrado en: {base_images_dir.resolve()}\")\n",
    "\n",
    "# Crear datasets\n",
    "ORIGINAL_IMG_SIZE = (28, 28)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    str(base_images_dir),\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=ORIGINAL_IMG_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    str(base_images_dir),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=ORIGINAL_IMG_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"✓ Clases: {class_names}\")\n",
    "print(f\"✓ Número de clases: {num_classes}\")\n",
    "\n",
    "# Optimizar datasets\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0708f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar datos\n",
    "train_ds_normalized = train_ds.map(lambda x, y: (x / 255.0, y))\n",
    "val_ds_normalized = val_ds.map(lambda x, y: (x / 255.0, y))\n",
    "\n",
    "print(\"✓ Datasets normalizados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d4f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir CNN desde cero\n",
    "cnn_model = models.Sequential([\n",
    "    # Capa convolucional 1\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Capa convolucional 2\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Capa convolucional 3\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    \n",
    "    # Capas densas\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "print(\"✓ Modelo CNN creado\")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8207546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar modelo\n",
    "cnn_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"✓ Modelo compilado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368ff1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    train_ds_normalized,\n",
    "    validation_data=val_ds_normalized,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b58cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo\n",
    "cnn_model.save(\"cnn_model_emociones.h5\")\n",
    "print(\"✓ Modelo guardado como 'cnn_model_emociones.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de entrenamiento\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Pérdida Entrenamiento', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Pérdida Validación', linewidth=2)\n",
    "axes[0].set_xlabel('Épocas')\n",
    "axes[0].set_ylabel('Pérdida')\n",
    "axes[0].set_title('Pérdida del Modelo CNN')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history.history['accuracy'], label='Precisión Entrenamiento', linewidth=2)\n",
    "axes[1].plot(history.history['val_accuracy'], label='Precisión Validación', linewidth=2)\n",
    "axes[1].set_xlabel('Épocas')\n",
    "axes[1].set_ylabel('Precisión')\n",
    "axes[1].set_title('Precisión del Modelo CNN')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Épocas entrenadas: {len(history.history['loss'])}\")\n",
    "print(f\"Precisión final validación: {history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536aa5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en validación\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for x_batch, y_batch in val_ds_normalized:\n",
    "    predictions = cnn_model.predict(x_batch, verbose=0)\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))\n",
    "    y_true.extend(y_batch.numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Matriz de Confusión - CNN')\n",
    "plt.ylabel('Verdadero')\n",
    "plt.xlabel('Predicho')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba con nueva imagen\n",
    "from PIL import Image\n",
    "\n",
    "image_path = \"../Dataset_emocional/feliz/feliz_01.jpg\"  # Cambiar por tu imagen\n",
    "image_path = Path(image_path)\n",
    "\n",
    "if not image_path.exists():\n",
    "    print(f\"❌ No se encontró: {image_path}\")\n",
    "else:\n",
    "    print(f\"✓ Imagen: {image_path.name}\")\n",
    "    \n",
    "    # Procesar\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img_resized = img.resize((28, 28))\n",
    "    img_array = np.array(img_resized) / 255.0\n",
    "    img_input = img_array.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    # Predicción\n",
    "    prediction = cnn_model.predict(img_input, verbose=0)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    \n",
    "    # Visualizar\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].imshow(img, cmap='gray')\n",
    "    axes[0].set_title(f\"Imagen: {image_path.name}\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    probabilities = prediction[0]\n",
    "    colors = ['#ff6b6b', '#4ecdc4', '#45b7d1']\n",
    "    axes[1].barh(class_names, probabilities, color=colors)\n",
    "    axes[1].set_xlabel('Probabilidad')\n",
    "    axes[1].set_title(f'Predicción: {class_names[predicted_class].upper()} ({confidence*100:.1f}%)')\n",
    "    axes[1].set_xlim([0, 1])\n",
    "    \n",
    "    for i, (emotion, prob) in enumerate(zip(class_names, probabilities)):\n",
    "        axes[1].text(prob + 0.02, i, f'{prob*100:.1f}%', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✓ Predicción: {class_names[predicted_class].upper()}\")\n",
    "    print(f\"Confianza: {confidence*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
